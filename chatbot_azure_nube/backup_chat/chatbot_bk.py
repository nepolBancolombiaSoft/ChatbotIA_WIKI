import os
import cohere
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.prompts import PromptTemplate
from config import COHERE_API_KEY

# ğŸ“Œ Configurar API de Cohere
co = cohere.Client(COHERE_API_KEY)

# ğŸ“Œ ConfiguraciÃ³n de la Base de Datos
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "wiki_db")

db = Chroma(persist_directory=DB_PATH, embedding_function=HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2"))
retriever = db.as_retriever()
print(f"ğŸ“‚ Base de datos guardada en: {DB_PATH}")

# ğŸ“Œ Historial de conversaciÃ³n
historial = []

# ğŸ“Œ Prompt optimizado para Cohere
qa_prompt = PromptTemplate(
    input_variables=["context", "question", "history"],
    template=(
        "Responde en **espaÃ±ol** de manera clara y precisa usando la informaciÃ³n de la Wiki.\n\n"
        "**Historial de conversaciÃ³n:**\n{history}\n\n"
        "**InformaciÃ³n relevante:**\n{context}\n\n"
        "**Pregunta:** {question}\n\n"
        "ğŸ“Œ **ExplicaciÃ³n clara y estructurada en espaÃ±ol:**"
    )
)

# ğŸ“Œ FunciÃ³n para actualizar el historial de conversaciÃ³n
def actualizar_historial(pregunta, respuesta):
    historial.append(f"Usuario: {pregunta}\nChatbot: {respuesta}")
    if len(historial) > 5:
        historial.pop(0)

# ğŸ“Œ Interfaz del chatbot en consola
while True:
    pregunta = input("\nğŸ”¹ Pregunta: ")
    if pregunta.lower() == "salir":
        print("ğŸ‘‹ Â¡Hasta luego! Si necesitas mÃ¡s ayuda, aquÃ­ estarÃ©. ğŸš€")
        break

    # ğŸ“Œ Buscar documentos relevantes
    documentos = retriever.invoke(pregunta)
    
    if documentos:
        print(f"ğŸ“„ {len(documentos)} documentos relevantes encontrados.")

        # âœ… Mostrar los documentos encontrados
        for idx, doc in enumerate(documentos[:3], 1):
            print(f"\nğŸ“„ **Documento {idx}:**")
            print(f"ğŸ“ **Extracto:** {doc.page_content[:400]}...")  # ğŸ”¹ Solo mostramos los primeros 400 caracteres
            print(f"ğŸ”— **URL:** {doc.metadata.get('source', 'âš ï¸ No disponible')}\n")

        # ğŸ“Œ Generar respuesta con Cohere API
        query = qa_prompt.format(
            question=pregunta,
            context="\n\n".join([doc.page_content[:300] for doc in documentos]),  
            history="\n".join(historial)
        )

        respuesta = co.generate(
            model="command",
            prompt=query,
            max_tokens=300,
            temperature=0.6,
            stop_sequences=["\n"]
            
        )

        respuesta_texto = respuesta.generations[0].text.strip()

        # ğŸ“Œ Guardar en el historial
        actualizar_historial(pregunta, respuesta_texto)

        # ğŸ“Œ Mostrar respuesta generada
        print(f"\nğŸ¤– **Respuesta generada:**\n{respuesta_texto}\n")

    else:
        print("âš ï¸ No encontrÃ© informaciÃ³n relevante. Intenta con otra pregunta.")
